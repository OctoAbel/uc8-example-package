pipeline {


   agent {label 'azubl00013'}
    environment {
	  GITREPO      		        = "/var/lib/jenkins/workspace/${env.JOB_NAME}"
	  GITREPOREMOTE   	        = "https://github.com/DIGITAL-FAB/DatabricksTemplateDev.git"
	  DBTOKEN                   = credentials('DBTOKEN')
	  DBURL          	        = credentials('DBURL')
	  LIBRARYPATH        	    = "${GITREPO}/Libraries"
	  BUILDPATH       	        = "${GITREPO}/Builds/${env.JOB_NAME}-${env.BUILD_NUMBER}"
	  OUTFILEPATH     	        = "${BUILDPATH}/Validation/Output"
	  TESTRESULTPATH  	        = "${BUILDPATH}/Validation/reports/junit"
	  CLUSTERID         	    = "0514-114706-parse443"
	  PYTHON_VENV_PATH	        = "/var/lib/jenkins/penv"
	  PYTHON_ENV        	    = "dbconnect"
	  HTTP_PROXY      	        = credentials('DBRICKS_HTTP_PROXY')
	  HTTPS_PROXY     	        = credentials('DBRICKS_HTTPS_PROXY')
	  NO_PROXY        	        = credentials('DBRICKS_NO_PROXY')
	  USERNAME_ARTIFCATORY      = credentials('USERNAME_MDA_ARTIFCATORY')
	  ////PWD_ARTIFACTORY           = credentials('PWD_MDA_ARTIFACTORY')
    }  
   stages {
      stage('Setup Databricks tools') {
	  steps {
	      withCredentials([string(credentialsId: "DBTOKEN", variable: 'TOKEN')]) {
		sh """#!/bin/bash
		    # Configure Conda environment for deployment & testing
		    source ${PYTHON_VENV_PATH}/${PYTHON_ENV}/bin/activate 

		    # Configure Databricks CLI for deployment
		    echo "${DBURL}
		    $TOKEN" | databricks configure --token

		    # Configure Databricks Connect for testing
		    echo "${DBURL}
		    $TOKEN
		    ${CLUSTERID}
			4169468764694708
		    15001" | databricks-connect configure
		   """
		

                stash includes: '**/*', name: 'library_build_test_databricks_dev', excludes: '**/.git/**'
		
                milestone 1
         }
        }
       }
      stage('Setup Python conf') {
			steps {
				sh """#!/bin/bash
			    # Enable Conda environment for tests
			    source ${PYTHON_VENV_PATH}/${PYTHON_ENV}/bin/activate 
				pip config set global.index-url  https://artifacts.st.com/artifactory/api/pypi/dit-mda-python/simple
				pip config set global.extra-index-url  https://artifacts.st.com/artifactory/api/pypi/dit-mda-python-local
				pip config set install.trusted-host  artifacts.st.com
				"""
				configFileProvider([configFile(fileId: 'MDA_pypirc', targetLocation: '/var/lib/jenkins/.pypirc')]) {
				   sh"""
				   echo 'username:${USERNAME_ARTIFCATORY}' >> /var/lib/jenkins/.pypirc
				   echo 'password:${PWD_ARTIFACTORY}' >> /var/lib/jenkins/.pypirc
				   """
				}
                milestone 2
			}
	  } 
      stage('Checkout') { // for display purposes
            steps {
                script {
                    currentBuild.displayName = "Build ${ENV:BUILD_NUMBER}"
                    currentBuild.description = "Build ${ENV:BUILD_NUMBER}, for commit ${ENV:GIT_COMMIT}"
                }

                checkout scm
                echo 'Checking out repo...'
               
		milestone 3
            }
      }
    stage('Run Unit Tests') {
	  steps {
	     script {
		  try {
		      sh """#!/bin/bash
			 # Enable Conda environment for tests
			 source ${PYTHON_VENV_PATH}/${PYTHON_ENV}/bin/activate 

			 # Python tests for libs
			 python3.7 -m pytest --junit-xml=${TESTRESULTPATH}/TEST-libout.xml ${LIBRARYPATH}/python/dbxdemo/test*.py || true
			 """
		  } catch(err) {
		    step([$class: 'JUnitResultArchiver', testResults: '--junit-xml=${TESTRESULTPATH}/TEST-*.xml'])
		    if (currentBuild.result == 'UNSTABLE')
		      currentBuild.result = 'FAILURE'
		    throw err
		  }
	     }
	     unstash 'library_build_test_databricks_dev'
		  
             milestone 4
	}
      }
	stage('Package') {
	  steps {
	  sh """#!/bin/bash
	      # Enable Conda environment for tests
	      source ${PYTHON_VENV_PATH}/${PYTHON_ENV}/bin/activate

	      # Package Python library to wheel
	      cd ${LIBRARYPATH}/python/dbxdemo
	      python3.7 setup.py sdist bdist_wheel
	     """
          stash includes: '**/*', name: 'library_build_deploy_databricks_dev', excludes: '**/.git/**'
		  
          milestone 5
	  }
	}
	stage('Build Artifact') {
	  steps {
	  sh """
		mkdir -p ${BUILDPATH}/Libraries/python
		mkdir -p ${BUILDPATH}/Validation/Output
		#Get Modified Files
		git diff --name-only --diff-filter=AMR HEAD^1 HEAD | xargs -I '{}' cp --parents -r '{}' ${BUILDPATH}

		# Get packaged libs
		find ${LIBRARYPATH} -name '*.whl' | xargs -I '{}' cp '{}' ${BUILDPATH}/Libraries/python/
		
		# Generate artifact
		tar -czvf Builds/latest_build.tar.gz ${BUILDPATH}
	     """
	  archiveArtifacts artifacts: 'Builds/latest_build.tar.gz'
          milestone 6
	  }
	}
	stage('Report Test Results') {
	  steps {
	  sh """find ${OUTFILEPATH} -name '*.json' -exec gzip --verbose {} \\;
		touch ${TESTRESULTPATH}/TEST-*.xml
	     """
	  junit "**/reports/junit/*.xml"
          unstash 'library_build_deploy_databricks_dev'
	  milestone 7
	  }
	}

	stage('Upload artifact') {
		steps{
			script {
				   def summary = junit testResults: "**/reports/junit/*.xml"
				   def totalCount = summary.totalCount.toString()
				   def passCount = summary.passCount.toString()
				   echo totalCount
				   echo passCount
				   
				   if(totalCount == passCount) { 
						echo 'BUILD STABLE: UPLOAD ARTIFACT'
						sh """
							source ${PYTHON_VENV_PATH}/${PYTHON_ENV}/bin/activate
							#unset HTTPS_PROXY
							#unset HTTP_PROXY
							cd ${LIBRARYPATH}/python/dbxdemo
							python3.7 setup.py sdist upload -r dit-mda-python-local
						   """
				    } else { 
						echo 'BUILD UNSTABLE: exit'
					}
				   
				}
		}
	}

	
   }


   post {
        aborted {
            node('master') {
                script {
                    currentBuild.description = "A newer build has caused this to be aborted"
                }
            }
        }
        cleanup {
            node('master') {
                cleanWs(patterns: [[pattern: '**/*', type: 'INCLUDE']])
            }
        }
    }
	
}